Chapter 57 – PlayCanvas VR: Building Immersive WebXR Experiences

Virtual Reality (VR) is an exciting frontier that PlayCanvas supports via the WebXR API, allowing immersive experiences directly in the browser—no plugins required. This chapter explores how to build, deploy, and optimize VR scenes in PlayCanvas.


---

1. Understanding WebXR in PlayCanvas

WebXR is the modern web standard for AR and VR. In PlayCanvas:

pc.XrManager handles XR session management

WebXR works on supported browsers (like Chrome) with devices such as Oculus Quest or HTC Vive


Check for support:

if (this.app.xr.supported) {
    console.log('WebXR supported');
}


---

2. Setting Up a VR-Ready Scene

To enable VR:

1. Ensure your app has the XrManager enabled


2. Add a button to enter VR


3. Use app.xr.start() with "immersive-vr"



button.element.on('click', () => {
    this.app.xr.start(pc.XRTYPE_VR, pc.XRSPACE_LOCALFLOOR);
});

Also make sure:

Your camera has the XRCamera component

The XRCamera is assigned to your active camera entity



---

3. Configuring the Camera for VR

The camera must:

Be centered and height-adjusted (user’s head position)

Move with the headset


cameraEntity.addComponent('camera', { clearColor: new pc.Color(0, 0, 0) });
cameraEntity.addComponent('xr-camera');

Use a floor-level reference space (pc.XRSPACE_LOCALFLOOR) for standing VR.


---

4. Creating VR Interactions

With VR controllers or hand tracking, you can interact with your world.

Detect controllers:

this.app.xr.input.on('inputsourceadded', (inputSource) => {
    console.log("Controller added", inputSource);
});

You can:

Cast rays from controllers to interact with objects

Detect button presses, grip, trigger

Provide haptic feedback



---

5. Adding Hands and Controllers

Add models for hands or controllers:

const modelEntity = new pc.Entity();
modelEntity.addComponent('model', {
    type: 'asset',
    asset: handAsset
});
inputSource.attach(modelEntity);

Use standard controller models or hand tracking (on supported devices).


---

6. Ray-Based Selection System

Let users point at UI or 3D objects:

Cast a ray from controller's forward direction

Use app.systems.rigidbody.raycastFirst or app.scene.raycaster.raycastAll()


Highlight or activate objects when hit.


---

7. UX Tips for VR

Design for comfort:

Keep frame rate at 72+ FPS

Avoid sudden motion; use teleportation instead of direct movement

Maintain scale: 1 unit = 1 meter


UI should be:

World-anchored

At comfortable viewing distances (1.5–2 meters)

Large enough to read easily



---

8. Optimization in VR

VR rendering is stereoscopic (two cameras), so it’s heavier than standard rendering.

To optimize:

Limit draw calls

Use lightmap instead of dynamic lighting

Reduce polygon count

Use efficient materials (e.g., Unlit when possible)

Avoid postprocessing unless necessary



---

9. Testing VR Locally

You can test:

In a desktop browser using WebXR emulator

On Oculus/Meta Quest using WebXR in the built-in browser

With a USB cable via Oculus Link + Chrome



---

10. Publishing and Deployment

No special deployment needed—WebXR is just HTML + JS.

Host your PlayCanvas build on:

GitHub Pages

Netlify / Vercel

Or directly on PlayCanvas hosting


Share a link and your users can enter VR right in the browser.


---

Summary: PlayCanvas supports fully immersive VR development using WebXR. With proper setup, interaction handling, and performance considerations, you can build VR games and apps that run on devices like Quest—all in the browser.

Next up:
Chapter 58 – Building AR Apps with PlayCanvas and WebXR.

