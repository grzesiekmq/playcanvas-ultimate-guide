Chapter 61 – Designing VR UI: Reticles, Gaze, and Interaction Models

User interfaces in VR must be rethought from the ground up. Without a traditional screen, keyboard, or mouse, interaction must rely on gaze, controllers, gestures, or ray-based input. In this chapter, we’ll explore PlayCanvas techniques for creating effective VR UIs using reticles, gaze-based selection, and interaction models that fit immersive contexts.


---

1. Reticle Fundamentals

A reticle (or crosshair) is a small visual aid shown at the center of the user’s view. It helps indicate where the user is looking and acts as a selection cursor in gaze-based interfaces.

Basic setup:

const entity = new pc.Entity("Reticle");
entity.addComponent("element", {
    type: "image",
    anchor: [0.5, 0.5, 0.5, 0.5],
    pivot: [0.5, 0.5],
    width: 0.03,
    height: 0.03,
    textureAsset: app.assets.find("reticle.png")
});
app.root.addChild(entity);

In VR mode, the reticle should be rendered on a separate layer locked to the headset’s view direction.


---

2. Gaze-Based UI: Hover to Activate

A common VR pattern is the gaze timer:

User looks at an object

A radial progress ring fills up

After n seconds, the action triggers


Core concept:

// Pseudo-logic
if (userIsLookingAt(button)) {
    timer += dt;
    if (timer > activationTime) {
        triggerAction();
    }
} else {
    timer = 0;
}

Enhance feedback with:

Animated fill rings

Color transitions

Audio cues (hover and select)



---

3. Ray-Based Interaction with Controllers

If your app supports VR controllers, use raycasting from the controller entity instead of head gaze.

Typical flow:

Cast a ray from the controller

Intersect with clickable UI surfaces

Display a laser pointer or highlight


const rayOrigin = controller.getPosition();
const rayDirection = controller.forward;
app.systems.rigidbody.raycastFirst(rayOrigin, rayDirection, hitResult);

Good UX practices:

Visualize the laser beam

Add hover effects when pointing

Require trigger press to activate



---

4. VR-Friendly UI Layout

Design constraints:

UI should be anchored in 3D space, not on a flat screen

Avoid putting UI directly on the headset

Use curved panels or 3D UI boards that feel natural at arm's length


Good placement:

1–2 meters from the user

Tilted slightly upward

In front of the user’s main view vector



---

5. Interaction Feedback

Visual feedback is key:

Change color on hover

Animate scale or glow on select

Play subtle sounds for hover/select

Add haptic feedback for controller clicks (if supported)


Example:

button.element.color = hovered ? pc.Color.YELLOW : pc.Color.WHITE;


---

6. Reticle + Ray Coexistence

Some apps use both gaze and ray input:

Gaze for passive scanning and simple selection

Ray for complex or precise input (e.g., sliders, tool menus)


Allow switching modes depending on user hardware:

if (app.xr.input && app.xr.input.controllers.length > 0) {
    useRayInteraction();
} else {
    useGazeInteraction();
}


---

7. Accessibility Considerations

Make VR UI accessible:

Avoid relying only on color (e.g., red/green)

Include voice narration or sound cues

Avoid tiny UI elements

Use large hitboxes



---

8. Creating 3D Buttons

3D buttons can be built using:

Plane entities

Collision components

Event listeners


Example:

buttonEntity.addComponent("collision", {
    type: "box",
    halfExtents: new pc.Vec3(0.2, 0.1, 0.01)
});
buttonEntity.addComponent("script");
buttonEntity.script.create("vrButton");


---

9. Reticle Scaling with Distance

To keep the reticle visible and readable:

Scale it dynamically based on distance

Clamp between min and max sizes


let scale = pc.math.clamp(distance * 0.01, 0.01, 0.05);
reticle.setLocalScale(scale, scale, scale);


---

10. Testing Interactions

Test with:

Oculus Quest (ideal)

WebXR emulator extension

Mouse/gaze fallbacks for desktop debug mode


Remember to test UI from a user’s seated or standing perspective.


---

Summary

VR UI design is about clarity, comfort, and immersion. Reticles, gaze timers, and ray-based input form the backbone of WebXR UI. With PlayCanvas, you can integrate all these techniques to deliver intuitive, immersive, and accessible virtual interfaces.


---

Next up:
Chapter 62 – Physics-Based Interaction in VR: Hands, Grabbing, and Collisions.

